{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5766bea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 12:27:33.921642: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "from load_scannet_data import export, export_with_2dseg\n",
    "import pdb\n",
    "from plyfile import PlyData, PlyElement\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00332816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.append(os.path.join('../deeplab'))\n",
    "from deeplab import run_semantic_segmentation_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d17c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNET_DIR = 'scans'\n",
    "EXPORTED_2D_DIR = 'frames_square'\n",
    "TRAIN_SCAN_NAMES = [line.rstrip() for line in open('meta_data/scannet_train.txt')]\n",
    "LABEL_MAP_FILE = 'meta_data/scannetv2-labels.combined.tsv'\n",
    "DONOTCARE_CLASS_IDS = np.array([])\n",
    "OBJ_CLASS_IDS = np.array([3,4,5,6,7,8,9,10,11,12,14,16,24,28,33,34,36,39])\n",
    "MAX_NUM_POINT = 50000\n",
    "#OUTPUT_FOLDER = './scannet_train_detection_data'\n",
    "OUTPUT_FOLDER = './scannet_train_detection_data_painted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd0ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_name = 'scene0000_00'\n",
    "#mesh_vertices, semantic_labels, instance_labels, instance_bboxes = export_one_scan_with_2dseg(scan_name, 'xx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908426c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply_rgb(points, colors, out_filename):\n",
    "    \"\"\" Color (N,3) points with RGB colors (N,3) within range [0,255] as OBJ file \"\"\"\n",
    "    colors = colors.astype(int)\n",
    "    N = points.shape[0]\n",
    "    vertex = []\n",
    "    for i in range(N):\n",
    "        c = colors[i,:]\n",
    "        vertex.append( (points[i,0],points[i,1],points[i,2],c[0],c[1],c[2]) )\n",
    "    vertex = np.array(vertex, dtype=[('x', 'f4'), ('y', 'f4'),('z', 'f4'),('red', 'u1'), ('green', 'u1'),('blue', 'u1')])\n",
    "    \n",
    "    el = PlyElement.describe(vertex, 'vertex', comments=['vertices'])\n",
    "    PlyData([el], text=True).write(out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f1287",
   "metadata": {},
   "source": [
    "## Import mesh, axis align matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8791eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_vertices = np.load(os.path.join('scannet_train_detection_data', scan_name)+'_vert.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fbf3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = os.path.join('scans', scan_name, scan_name + '.txt') # includes axisAlignment info for the train set scans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf335376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scene axis alignment matrix\n",
    "lines = open(meta_file).readlines()\n",
    "for line in lines:\n",
    "    if 'axisAlignment' in line:\n",
    "        axis_align_matrix = [float(x) \\\n",
    "            for x in line.rstrip().strip('axisAlignment = ').split(' ')]\n",
    "    if 'colorWidth' in line:\n",
    "        colorW = int(line.strip('colorWidth = ').split(' ')[0])\n",
    "    if 'colorHeight' in line:\n",
    "        colorH = int(line.strip('colorHeight = ').split(' ')[0])\n",
    "\n",
    "axis_align_matrix = np.array(axis_align_matrix).reshape((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb454ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alinged_verts = np.ones((mesh_vertices.shape[0],4))\n",
    "alinged_verts[:,:3] = mesh_vertices[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "083d0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse axis alignment, to match color coordinates\n",
    "unalign_verts = np.dot(alinged_verts, np.linalg.inv(axis_align_matrix.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d761947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matrix(filepath):\n",
    "    out_matrix = np.zeros((4,4))\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        i = 0\n",
    "        for line in lines:\n",
    "            values = line.strip().split(' ')\n",
    "            for j in range(4):\n",
    "                out_matrix[i,j] = values[j]\n",
    "            i += 1\n",
    "    return out_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb25a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_scan_dir = os.path.join('frames_square', scan_name)\n",
    "color_intrinsic_file = os.path.join(exported_scan_dir, 'intrinsic', 'intrinsic_color.txt')   \n",
    "color_intrinsic = read_matrix(color_intrinsic_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5cd6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=0\n",
    "pose_file = os.path.join(exported_scan_dir, 'pose', str(frame) + '.txt')\n",
    "img_file = os.path.join(exported_scan_dir, 'color', str(frame) + '.jpg')\n",
    "\n",
    "# read pose matrix(Rotation and translation)\n",
    "pose_matrix = read_matrix(pose_file)   \n",
    "\n",
    "sampled_h = np.ones((len(unalign_verts), 4))\n",
    "sampled_h[:,:3] = unalign_verts[:,:3]\n",
    "\n",
    "camera_coord = np.matmul(np.linalg.inv(pose_matrix), np.transpose(sampled_h))\n",
    "camera_proj = np.matmul(color_intrinsic, camera_coord)\n",
    "\n",
    "# Get valid points for the image\n",
    "x = camera_proj[0,:]\n",
    "y = camera_proj[1,:]\n",
    "z = camera_proj[2,:]\n",
    "filter_idx = np.where((x/z >= 0) & (x/z < colorW) & (y/z >= 0) & (y/z < colorH) & (z > 0))[0]\n",
    "\n",
    "# Normalize by 4th coords(Homogeneous -> 3 coords system)\n",
    "camera_proj_normalized = camera_proj / camera_proj[2,:]\n",
    "\n",
    "#Get 3d -> 2d mapping\n",
    "projected = camera_proj_normalized[:2, filter_idx]\n",
    "\n",
    "#Reduce to 320,240 size\n",
    "camera_proj_sm = np.zeros((5, projected.shape[-1]))\n",
    "\n",
    "camera_proj_sm[0,:] = projected[0,:] * 320/colorW\n",
    "camera_proj_sm[1,:] = projected[1,:] * 240/colorH\n",
    "\n",
    "# Get pixel index\n",
    "x = camera_proj_sm[0,:].astype(np.uint8)\n",
    "y = camera_proj_sm[1,:].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea3fa273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use depth information to remove occluded points(NOt available from 2d images)\n",
    "depth_file = os.path.join(exported_scan_dir, 'depth', str(frame) + '.png')\n",
    "\n",
    "depth_img = Image.open(depth_file)\n",
    "depth_np = np.array(depth_img)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "294b6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_filter = np.where(depth_np[y,x]/1000 * 1.1 > camera_proj[2,filter_idx])[0]\n",
    "filter_idx2 = np.take(filter_idx, depth_filter)\n",
    "\n",
    "x = x[depth_filter]\n",
    "y = y[depth_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3be2bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_idx2 = np.take(filter_idx, depth_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34dcadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = np.load(os.path.join('semantic_2d_results','scene0191_01','prob_1160.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09d901f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.argmax(pred_prob,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0499964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26f0cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 14:55:39.672568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-05-01 14:55:39.673788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-01 14:55:39.673831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-01 14:55:39.673836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-05-01 14:55:39.673840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-05-01 14:55:39.675046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22318 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:25:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "## Preparation for pointpainting    \n",
    "n_classes = 18\n",
    "\n",
    "# deeplabv3+ tf session\n",
    "INPUT_SIZE = (321, 321)    \n",
    "with tf.compat.v1.gfile.GFile('../deeplab/saved_model/scannet_2.pb', \"rb\") as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "myGraph = tf.compat.v1.Graph()\n",
    "with myGraph.as_default():\n",
    "    tf.compat.v1.import_graph_def(graph_def, name='')\n",
    "\n",
    "sess = tf.compat.v1.Session(graph=myGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d95f442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sementationr esult\n",
    "img = Image.open(img_file)\n",
    "pred_prob, pred_class = run_semantic_segmentation_graph(img, sess, INPUT_SIZE)\n",
    "pred_prob = pred_prob[:,:,:(n_classes+1)] # 0 is background class\n",
    "\n",
    "pred_prob = pred_prob[y, x]\n",
    "projected_class = pred_class[y, x]    \n",
    "\n",
    "isPainted = np.where((projected_class > 0) & (projected_class < n_classes+1), 1, 0) # Point belongs to foreground?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70788689",
   "metadata": {},
   "outputs": [],
   "source": [
    "painted_verts = np.zeros((alinged_verts.shape[0], 3 + (1 + 1 + n_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dab17055",
   "metadata": {},
   "outputs": [],
   "source": [
    "painted_verts[:,:3] = alinged_verts[:,:3]\n",
    "painted_verts[filter_idx,3] = isPainted\n",
    "painted_verts[filter_idx,4:] = pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49607389",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_vertices2 = np.zeros((50000, 6))\n",
    "mesh_vertices2[:,:3] = painted_verts[:,:3]\n",
    "mesh_vertices2[:,3:] = np.tile(255*painted_verts[:,3,None], (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "feeb6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ply_rgb(mesh_vertices2[:,:3], mesh_vertices2[:,3:], \"painting_test_sample.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c7904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
